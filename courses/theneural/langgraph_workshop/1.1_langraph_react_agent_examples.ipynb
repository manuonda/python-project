{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8759a11",
   "metadata": {},
   "source": [
    "### 1 React Agent con Router y Especialista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b6e5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool \n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiplies two numbers.\"\"\"\n",
    "    result = a * b\n",
    "    return f\"El resultado es: {a * b} = {result}\"\n",
    "\n",
    "@tool\n",
    "def sum(a: float, b: float) -> float:\n",
    "    \"\"\"Sums two numbers.\"\"\"\n",
    "    result = a + b\n",
    "    return f\"El resultado es: {a} + {b} = {result}\"\n",
    "\n",
    "@tool \n",
    "def web_search(quer:str) -> str:\n",
    "    \"\"\"Realiza una b√∫squeda en la web y devuelve un resumen de los resultados.\"\"\"\n",
    "    simulated_results = {\n",
    "        \"python programming\": \"Python es un lenguaje de programaci√≥n interpretado, de alto nivel y de prop√≥sito general.\",\n",
    "        \"langchain\": \"LangChain es un marco para desarrollar aplicaciones impulsadas por modelos de lenguaje.\",\n",
    "        \"openai\": \"OpenAI es una organizaci√≥n de investigaci√≥n en inteligencia artificial que desarrolla y promueve IA amigable.\"\n",
    "    }\n",
    "    for key in simulated_results:\n",
    "        if key in quer.lower():\n",
    "            return simulated_results[key]\n",
    "    return \"No se encontraron resultados relevantes.\"\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Evalue expresiones matematicas complejas.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return f\"El resultado de la expresi√≥n '{expression}' es: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error al evaluar la expresi√≥n: {e}\"\n",
    "\n",
    "\n",
    "TOOLS = [multiply, sum, web_search, calculator]\n",
    "\n",
    "#configuration LLM and tools \n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(TOOLS, parallel_tool_calls=False)\n",
    "\n",
    "#Router inteligente\n",
    "def router_by_task(state: MessagesState) -> Literal[\"math_specialist\", \"research_specialist\", \"general\", \"end\"]:\n",
    "    \"\"\"Enruta segun el tipo de tarea detectada\"\"\"\n",
    "    last_message = state[\"messages\"][-1].content.lower()\n",
    "    print(\"=== router_by_task\")\n",
    "    print(f\"last_message: {last_message}\")\n",
    "\n",
    "    # detectar matematicas\n",
    "    math_keywords = [\"multiplica\", \"suma\", \"calcula\", \"resultado\", \"operaci√≥n\", \"√ó\", \"+\", \"-\", \"*\"]\n",
    "    if any(keyword in last_message for keyword in math_keywords):\n",
    "        return \"math_specialist\"\n",
    "\n",
    "    # Detectar investigaci√≥n\n",
    "    research_keywords = [\"busca\", \"investiga\", \"informaci√≥n\", \"qu√© es\", \"explica\", \"search\"]\n",
    "    if any(keyword in last_message for keyword in research_keywords):\n",
    "        return \"research_specialist\"\n",
    "\n",
    "    # Verificar si hay tool_calls pendientes\n",
    "    last_ai_message = next((msg for msg in reversed(state[\"messages\"]) if hasattr(msg, \"tool_calls\")), None)\n",
    "    if last_ai_message and getattr(last_ai_message, \"tool_calls\", []):\n",
    "        return \"general\"\n",
    "\n",
    "    return \"end\"\n",
    "   \n",
    "\n",
    "def math_specialist(state: MessagesState):\n",
    " \"\"\" Especialista en matemtaicas y calculos \"\"\"\n",
    " system_msg = SystemMessage(content=\"\"\"Eres un matem√°tico experto. \n",
    "    - Analiza el problema paso a paso\n",
    "    - Usa las herramientas disponibles (multiply, sum_numbers, calculator)\n",
    "    - Explica tu razonamiento antes de calcular\n",
    "    - Verifica los resultados\n",
    "    \"\"\")\n",
    " response = llm_with_tools.invoke([system_msg] + state[\"messages\"])\n",
    " return {\"messages\": [response]} \n",
    "\n",
    "def research_specialist(state: MessagesState):\n",
    "    \"\"\"Especialista en investigaci√≥n y b√∫squedas\"\"\"\n",
    "    system_msg = SystemMessage(content=\"\"\"Eres un investigador experto.\n",
    "    - Usa web_search para encontrar informaci√≥n\n",
    "    - Resume los hallazgos de forma clara y concisa\n",
    "    - Cita las fuentes cuando sea relevante\n",
    "    - Proporciona contexto √∫til\n",
    "    \"\"\")\n",
    "    response = llm_with_tools.invoke([system_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def general_assistant(state: MessagesState):\n",
    "    \"\"\"Asistente general para otras consultas\"\"\"\n",
    "    system_msg = SystemMessage(content=\"\"\"Eres un asistente √∫til y vers√°til.\n",
    "    - Responde de forma clara y directa\n",
    "    - Usa herramientas cuando sea necesario\n",
    "    - Mant√©n un tono amigable y profesional\n",
    "    \"\"\")\n",
    "    response = llm_with_tools.invoke([system_msg] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "#contruimos el grafo \n",
    "graph = StateGraph(MessagesState)\n",
    "toolNode = ToolNode(TOOLS)\n",
    "\n",
    "#agregar nodos \n",
    "# no entiend lo que sigue ? graph.add_node(\"router\", lambda state: {\"messages\": state[\"messages\"]})\n",
    "\n",
    "graph.add_node(\"router\", lambda state: {\"messages\": state[\"messages\"]})\n",
    "\n",
    "graph.add_node(\"math_specialist\", math_specialist)\n",
    "graph.add_node(\"research_specialist\",research_specialist)\n",
    "graph.add_node(\"general\",general_assistant)\n",
    "graph.add_node(\"tools\",toolNode)\n",
    "\n",
    "#configura edges \n",
    "graph.add_edge(START,\"router\")\n",
    "# üîÑ CONDITIONAL EDGE: Decisi√≥n inteligente basada en el contenido\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",           # 1Ô∏è‚É£ Nodo origen: desde donde se toma la decisi√≥n\n",
    "    router_by_task,     # 2Ô∏è‚É£ Funci√≥n decisora: analiza el state y retorna una string\n",
    "    {\n",
    "        # 3Ô∏è‚É£ Mapeo: salida_de_funci√≥n ‚Üí nodo_destino\n",
    "        # KEY (lo que retorna router_by_task) ‚Üí VALUE (nodo al que ir)\n",
    "        \n",
    "        \"math_specialist\": \"math_specialist\",        # Si retorna \"math_specialist\" ‚Üí va al nodo \"math_specialist\"\n",
    "        \"research_specialist\": \"research_specialist\", # Si retorna \"research_specialist\" ‚Üí va al nodo \"research_specialist\"  \n",
    "        \"general\": \"general\",                        # Si retorna \"general\" ‚Üí va al nodo \"general\"\n",
    "        \"end\": \"__end__\"                            # Si retorna \"end\" ‚Üí termina el grafo (nodo especial END)\n",
    "    }\n",
    ")\n",
    "# cada especialista puede llamar a las tools \n",
    "graph.add_conditional_edges(\"math_specialist\", tools_condition)\n",
    "graph.add_conditional_edges(\"research_specialist\", tools_condition)\n",
    "graph.add_conditional_edges(\"general\", tools_condition)\n",
    "\n",
    "#despues de usar tools vovler al router \n",
    "graph.add_edge(\"tools\",\"router\")\n",
    "\n",
    "#compilar\n",
    "advanced_router_agent = graph.compile()\n",
    "\n",
    "#display(Image(advanced_router_agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bba947e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiplica 25 por 8 y luego suma 100 al resultado\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_8pdkoYiKGOLxNPB1iYIwNhbj)\n",
      " Call ID: call_8pdkoYiKGOLxNPB1iYIwNhbj\n",
      "  Args:\n",
      "    a: 25\n",
      "    b: 8\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "El resultado es: 200.0 = 200.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  sum (call_2NBvmuRwbV9kOn2nhdmzCztA)\n",
      " Call ID: call_2NBvmuRwbV9kOn2nhdmzCztA\n",
      "  Args:\n",
      "    a: 200\n",
      "    b: 100\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: sum\n",
      "\n",
      "El resultado es: 200.0 + 100.0 = 300.0\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "El resultado de multiplicar 25 por 8 es 200. Luego, al sumarle 100 al resultado obtenemos 300.\n"
     ]
    }
   ],
   "source": [
    "result1 = advanced_router_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Multiplica 25 por 8 y luego suma 100 al resultado\")]\n",
    "    })\n",
    "for msg in result1[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61709e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== router_by_task\n",
      "last_message: busca informaci√≥n sobre langgraph y expl√≠came qu√© es\n",
      "=== router_by_task\n",
      "last_message: no se encontraron resultados relevantes.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Busca informaci√≥n sobre LangGraph y expl√≠came qu√© es\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  web_search (call_NoHH9nB8eDx0tDQyJvn4LlXD)\n",
      " Call ID: call_NoHH9nB8eDx0tDQyJvn4LlXD\n",
      "  Args:\n",
      "    quer: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: web_search\n",
      "\n",
      "No se encontraron resultados relevantes.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "No pude encontrar informaci√≥n espec√≠fica sobre LangGraph en la web. Sin embargo, bas√°ndome en mi conocimiento matem√°tico, puedo decirte que \"LangGraph\" podr√≠a referirse a un grafo que representa relaciones entre lenguajes de programaci√≥n. Los grafos son estructuras matem√°ticas que consisten en nodos (v√©rtices) y aristas (conexiones) que los unen.\n",
      "\n",
      "Si deseas m√°s informaci√≥n espec√≠fica sobre LangGraph, te recomendar√≠a buscar en fuentes especializadas en lenguajes de programaci√≥n o en el √°mbito de la teor√≠a de grafos.\n"
     ]
    }
   ],
   "source": [
    "result2 = advanced_router_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Busca informaci√≥n sobre LangGraph y expl√≠came qu√© es\")]\n",
    "})\n",
    "for msg in result2[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "700549fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== router_by_task\n",
      "last_message: busca informaci√≥n sobre langchain y expl√≠came qu√© es\n",
      "=== router_by_task\n",
      "last_message: langchain es un marco para desarrollar aplicaciones impulsadas por modelos de lenguaje.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Busca informaci√≥n sobre langchain y expl√≠came qu√© es\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  web_search (call_TaSfNS9X5YIKbra9o862MP4g)\n",
      " Call ID: call_TaSfNS9X5YIKbra9o862MP4g\n",
      "  Args:\n",
      "    quer: langchain\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: web_search\n",
      "\n",
      "LangChain es un marco para desarrollar aplicaciones impulsadas por modelos de lenguaje.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangChain es un marco para desarrollar aplicaciones impulsadas por modelos de lenguaje. Es una herramienta que facilita la creaci√≥n de aplicaciones basadas en modelos de lenguaje.\n"
     ]
    }
   ],
   "source": [
    "result2 = advanced_router_agent.invoke({\n",
    "        \"messages\": [HumanMessage(content=\"Busca informaci√≥n sobre langchain y expl√≠came qu√© es\")]\n",
    "})\n",
    "for msg in result2[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
