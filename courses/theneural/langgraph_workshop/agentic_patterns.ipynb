{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e0ced1",
   "metadata": {},
   "source": [
    "### Agent Reflection\n",
    "Agent Reflection is a process where an AI agent reviews its own actions, decisions, and outcomes to improve its performance over time. This involves analyzing past interactions, identifying areas for improvement, and making adjustments to strategies or behaviors.\n",
    "\n",
    "#spanish\n",
    "### Reflexión del Agente\n",
    "La Reflexión del Agente es un proceso en el que un agente de IA revisa sus propias acciones, decisiones y resultados para mejorar su rendimiento con el tiempo. Esto implica analizar interacciones pasadas, identificar áreas de mejora y hacer ajustes en estrategias o comportamientos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import SystemMessage, HummanMessage \n",
    "from langgraph.graph import StateGraph, MessagesState, START, END \n",
    "from typing import TypedDict, List\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\"\"\"Nodo que crea o mejor el contenido\"\"\"\n",
    "def generator_node(state):\n",
    "    \"\"\"Generator Node - \"El escritor del sistema\n",
    "    Responsabilidades:\n",
    "    - Generar contenido inicial \n",
    "    - Mejorar Contendio basandose en el feedback \n",
    "    - Producir respuesta de calidad \n",
    "    \n",
    "    \"\"\"\n",
    "    llm = init_chat_model(model=\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "    if state.get(\"reflection\"):\n",
    "        prompt = f\"\"\"\n",
    "         Tarea : Mejorar el siguiente contenido\n",
    "\n",
    "         CONTENIDO ACTUAL: {state['draft']}\n",
    "         FEEDBACK RECIBIDO: {state['reflection']}\n",
    "         SOLICITUD ORIGINAL: {state['messages'][-1].content}\n",
    "\n",
    "         Genera una version mejorada que aborde todos los puntos del feedback \n",
    "        \"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "         TAREA: Generar contenido de alta calidad \n",
    "         SOLICITUD: {state['messages'][-1].content} \n",
    "         Crea una respuesta completa, clara y util\n",
    "        \"\"\"\n",
    "\n",
    "    response = llm.invoke([HummanMessage(content=prompt)])\n",
    "\n",
    "    return {\n",
    "        \"draft\": response.content,\n",
    "        \"iterations\": state.get(\"iterations\",0) + 1\n",
    "    }\n",
    "\n",
    "def should_continue_re\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
