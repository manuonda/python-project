{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e0ced1",
   "metadata": {},
   "source": [
    "### Agent Reflection\n",
    "Agent Reflection is a process where an AI agent reviews its own actions, decisions, and outcomes to improve its performance over time. This involves analyzing past interactions, identifying areas for improvement, and making adjustments to strategies or behaviors.\n",
    "\n",
    "#spanish\n",
    "### Reflexión del Agente\n",
    "La Reflexión del Agente es un proceso en el que un agente de IA revisa sus propias acciones, decisiones y resultados para mejorar su rendimiento con el tiempo. Esto implica analizar interacciones pasadas, identificar áreas de mejora y hacer ajustes en estrategias o comportamientos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import SystemMessage, HummanMessage \n",
    "from langgraph.graph import StateGraph, MessagesState, START, END \n",
    "from typing import Literal, TypedDict, List\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class ReflectionState(MessagesState):\n",
    "    draft: str = \"\" #Borrador actual\n",
    "    reflection: str = \"\" #Feedback del critico\n",
    "    iterations: int = 0 #Numero de iteraciones realizadas\n",
    "    max_iterations: int = 3 #maximo de iteraciones permitidas \n",
    "    \n",
    "\n",
    "\"\"\"Nodo que crea o mejor el contenido\"\"\"\n",
    "def generator_node(state):\n",
    "    \"\"\"Generator Node - \"El escritor del sistema\n",
    "    Responsabilidades:\n",
    "    - Generar contenido inicial \n",
    "    - Mejorar Contendio basandose en el feedback \n",
    "    - Producir respuesta de calidad \n",
    "    \n",
    "    \"\"\"\n",
    "    llm = init_chat_model(model=\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "\n",
    "    if state.get(\"reflection\"):\n",
    "        prompt = f\"\"\"\n",
    "         Tarea : Mejorar el siguiente contenido\n",
    "\n",
    "         CONTENIDO ACTUAL: {state['draft']}\n",
    "         FEEDBACK RECIBIDO: {state['reflection']}\n",
    "         SOLICITUD ORIGINAL: {state['messages'][-1].content}\n",
    "\n",
    "         Genera una version mejorada que aborde todos los puntos del feedback \n",
    "        \"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "         TAREA: Generar contenido de alta calidad \n",
    "         SOLICITUD: {state['messages'][-1].content} \n",
    "         Crea una respuesta completa, clara y util\n",
    "        \"\"\"\n",
    "\n",
    "    response = llm.invoke([HummanMessage(content=prompt)])\n",
    "\n",
    "    return {\n",
    "        \"draft\": response.content,\n",
    "        \"iterations\": state.get(\"iterations\",0) + 1\n",
    "    }\n",
    "\n",
    "def reflection_node(state: ReflectionState):\n",
    "    \"\"\" Reflectio Node - El critico del sistema \n",
    "        Responsabilidades :\n",
    "        - Analizar el contenido generado \n",
    "        - Identificar areas de mejora \n",
    "        - Proporcionar feedback constructivo\n",
    "    \"\"\"\n",
    "    \n",
    "    llm = init_chat_model(model=\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "       Eres un critico experto que evalua el contenido \n",
    "       \n",
    "       CONTENIDO A EVALUAR \n",
    "       {state['draft']}\n",
    "       \n",
    "       SOLICITUD ORIGINAL:\n",
    "       {state['messages'][-1].content}\n",
    "       \n",
    "       Analiza el contenido y proporciona el feedback constructivo\n",
    "       1- Claridad y estructura \n",
    "       2- Completitud de la respuesta \n",
    "       3- Precision tecnica \n",
    "       4- Areas especificas de mejora \n",
    "       \n",
    "       Si el contenido es excelente, indica \"APROBADO - El contenido cumple todos los criterios \n",
    "       Si necesitas mejoras, proporciona puntos especificos a mejorar\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([HummanMessage(content=prompt)])\n",
    "    \n",
    "    return {\n",
    "        \"reflection\": response.content,\n",
    "        \"messages\": state[\"messages\"]\n",
    "    } \n",
    "    \n",
    "    \n",
    "def should_continue_reflection(state: ReflectionState) -> Literal[\"reflect\",\"end\"]:\n",
    "    \"\"\" Decide si continuar refinando o terminar\n",
    "    \n",
    "    Criterios:\n",
    "     - Si alcanzo max_iterations -> terminar \n",
    "     - Si el feedback indica \"Aprobado\" ->terminar\n",
    "     - De lo contrario -> continuar reflexionando  \n",
    "    \"\"\"    \n",
    "    \n",
    "    #Verifica limite de iteraciones\n",
    "    if state['max_iterations'] >= state.get(\"max_iterations\", 3):\n",
    "        print(f\"Limite de iteraciones alcanzado ({state['iterations']})\")\n",
    "        return \"end\"\n",
    "    \n",
    "    if state.get(\"reflection\") and \"APROBADO\" in state[\"reflection\"]:\n",
    "        print(f\"Contenido aprobado en interacion : {state[\"iterations\"]}\")\n",
    "        return \"end\"\n",
    "    \n",
    "    print(f\"Iteracion {state['iterations']}: Refinando contenido...\")\n",
    "    return \"reflect\"\n",
    "\n",
    "  \n",
    "graph = StateGraph(ReflectionState)\n",
    "graph.add_node(\"generator\",generator_node)\n",
    "graph.add_node(\"reflection\", reflection_node)\n",
    "graph.add_edge(START, \"generator\")\n",
    "graph.add_conditional_edges(\n",
    "    \"generator\",\n",
    "    should_continue_reflection,\n",
    "    {\n",
    "        \"end\":END,\n",
    "        \"reflect\":\"reflection\"\n",
    "    }\n",
    ")\n",
    "graph.add_edge(\"reflection\", \"generator\")\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
