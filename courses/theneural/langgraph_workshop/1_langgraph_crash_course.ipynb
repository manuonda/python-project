{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LangGraph Crash Course"],"metadata":{"id":"tTZBIQSu93SG"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1bwlbmjbPZLXBizw5Ekl7icGgjiDM7RQP\" alt=\"Alt text\" width=\"700\"/>\n"],"metadata":{"id":"Qo9wCEoayZDc"}},{"cell_type":"markdown","source":["LangGraph is a framework designed for building **complex, stateful LLM agent and multi-agent applications**.\n","\n","Unlike traditional linear workflows, LangGraph uses a **graph-based architecture** that gives developers fine-grained control over agent behaviorâ€”enabling features like conditional logic, tool prioritization, looping, and shared memory.\n","\n","It's ideal for creating **robust, production-ready AI systems** that require precision and adaptability."],"metadata":{"id":"nRgGv-rSlnxz"}},{"cell_type":"markdown","source":["The first thing we need to do, is to install a bunch of **Python libraries** we'll need throughout this crash course."],"metadata":{"id":"5ALQRGppAUlL"}},{"cell_type":"code","source":["%%capture --no-stderr\n","%pip install --quiet -U langchain_openai langchain_core langchain_community langgraph"],"metadata":{"id":"uTsQRGPsAivn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Understanding LangGraph Structure"],"metadata":{"id":"END_1VL81Xp9"}},{"cell_type":"markdown","source":["Let's start by understanding the fundamental components of LangGraph and how to create a simple graph.\n"],"metadata":{"id":"PCRbcHmP1s1U"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1HlCxqbbJ_xyIFCSimyPKAS_MVcGnne7J\" alt=\"Alt text\" width=\"700\"/>\n"],"metadata":{"id":"ralsZgLk2Dev"}},{"cell_type":"markdown","source":["Remember that LangGraph is based on three fundamental components: **state**, **nodes**, and **edges**. Let's start with the state."],"metadata":{"id":"OfcmdSXg2Rnc"}},{"cell_type":"markdown","source":["## 1. State"],"metadata":{"id":"1Dvy-4sS2RUd"}},{"cell_type":"markdown","source":["Start by defining the State of the graph.\n","\n","This state schema acts as the input structure for all Nodes and Edges within the graph."],"metadata":{"id":"1DwQb0uC2zuP"}},{"cell_type":"code","source":["from typing_extensions import TypedDict\n","\n","class State(TypedDict):\n","    graph_state: str"],"metadata":{"id":"2uNqdklm2yV5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Nodes"],"metadata":{"id":"-CrRpjxy3AXD"}},{"cell_type":"markdown","source":["**Nodes are simply Python functions.**\n","\n","Each node takes the state as its first positional argument, based on the previously defined `TypedDict` schema.\n","\n","Since the state includes a `graph_state` key, each node can access it using `state['graph_state']`.\n","\n","> Each node returns an updated value for graph_state, and by default, this new value will overwrite the existing one in the state."],"metadata":{"id":"glHwFXO-3Hra"}},{"cell_type":"code","source":["def node_1(state):\n","    print(\"---Node 1---\")\n","    return {\"graph_state\": state['graph_state'] +\" Welcome\"}\n","\n","def node_2(state):\n","    print(\"---Node 2---\")\n","    return {\"graph_state\": state['graph_state'] +\" to the DataHack Summit!\"}\n","\n","def node_3(state):\n","    print(\"---Node 3---\")\n","    return {\"graph_state\": state['graph_state'] +\" to Bengaluru!\"}\n"],"metadata":{"id":"D895TRzh2yUG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Edges"],"metadata":{"id":"D-5NMLG23nuk"}},{"cell_type":"markdown","source":["Edges define the connections between nodes in the graph.\n","\n","* **Normal edges** are used when you always want to transition from one node to anotherâ€”for example, from `node_1` to `node_2`.\n","\n","* **Conditional edges** allow for **dynamic routing** based on logic. These are implemented as functions that evaluate the current state and return the name of the next node to execute."],"metadata":{"id":"js2GBldx3tKc"}},{"cell_type":"code","source":["import random\n","from typing import Literal\n","\n","def decide_node(state) -> Literal[\"node_2\", \"node_3\"]:\n","\n","    user_input = state['graph_state']\n","\n","    if random.random() < 0.5:\n","        return \"node_2\"\n","\n","    return \"node_3\""],"metadata":{"id":"AY1I6P4G3nMI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Graph Construction"],"metadata":{"id":"Yf7XAzTW4J0w"}},{"cell_type":"markdown","source":["Now it's time to build the graph using the components we've defined.\n","\n","We'll use the `StateGraph` class to create the graph structure.\n","\n","First, initialize a `StateGraph` with the `State` schema we defined earlier.\n","\n","> Then, add your nodes and connect them with edges.\n","\n","Use the special `START` node to define the entry point of the graphâ€”this is where user input enters the system.\n","\n","The `END` node marks the terminal point where the graph finishes execution.\n","\n","Once all nodes and edges are added, compile the graph to validate its structure.\n","\n","You can also visualize the resulting graph as a **Mermaid diagram** for a clearer view of the workflow."],"metadata":{"id":"QlouhAVD4TVO"}},{"cell_type":"code","source":["from IPython.display import Image, display\n","from langgraph.graph import StateGraph, START, END\n","\n","# Build graph\n","builder = StateGraph(State)\n","\n","# Defining the nodes\n","builder.add_node(\"node_1\", node_1)\n","builder.add_node(\"node_2\", node_2)\n","builder.add_node(\"node_3\", node_3)\n","\n","# Logic - Defining the edges\n","builder.add_edge(START, \"node_1\")\n","builder.add_conditional_edges(\"node_1\", decide_node)\n","builder.add_edge(\"node_2\", END)\n","builder.add_edge(\"node_3\", END)\n","\n","# Compile the Graph\n","graph = builder.compile()\n","\n","# View\n","display(Image(graph.get_graph().draw_mermaid_png()))"],"metadata":{"id":"YhTyQ5HS2yPr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Graph Execution"],"metadata":{"id":"lMpm5Hqr4tsc"}},{"cell_type":"markdown","source":["The compiled graph conforms to the `Runnable` protocol, which defines a standard interface for executing LangChain components.\n","\n","One of the key methods in this interface is `.invoke()`.\n","\n","You start by passing an input dictionary, such as `{\"graph_state\": \"Hi there, it's Miguel!\"}`, to set the initial value of the graph state.\n","\n","When `.invoke()` is called, execution begins at the `START` node.\n","\n","The graph then proceeds through the defined nodes (`node_1`, `node_2`, `node_3`), following the structure you built.\n","\n","A conditional edge determines whether the flow goes from `node_1` to `node_2` or `node_3`, based on a 50/50 logic split.\n","\n","Each node receives the current state, processes it, and returns an updated value, which replaces the previous graph_state.\n","\n","Execution continues along the graph until the END node is reached, signaling completion."],"metadata":{"id":"HJg76tS040BU"}},{"cell_type":"code","source":["graph.invoke({\"graph_state\" : \"Hi there, it's Miguel!\"})"],"metadata":{"id":"bol3DOcN2yNM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Congratulations, now we have an idea of how LangGraph works. Time to see what kind of LLM applications we can build with this framework!"],"metadata":{"id":"cm9il5oJ5lFj"}},{"cell_type":"markdown","source":["# Building LLM Applications with LangGraph"],"metadata":{"id":"cz5QZJXN59KK"}},{"cell_type":"markdown","source":["Our **Telegram Agent** will follow a pattern known as the **Router**, in which the LLM decides which workflow to follow.\n","\n","**This Router is an evolution of static LLM Chains.**\n","\n","Let's take a look at how to implement each one in the following sections.\n","\n","> Don't forget about the Levels of Autonomy in LLM Applications! ðŸ‘‡\n"],"metadata":{"id":"n0i3DRzCytse"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1eQtFcYG3Elfdl0_jCGEgM7bUTiv-o213\" alt=\"Alt text\" width=\"700\"/>\n"],"metadata":{"id":"8YRinf5pz5p8"}},{"cell_type":"markdown","source":["## Chains"],"metadata":{"id":"H7aabVNF5FMF"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1SKEFGB3PXL6UVCAYBXA7ZhW_Dobu3ht3\" alt=\"Alt text\" width=\"700\"/>"],"metadata":{"id":"gi_QvuDz9hd5"}},{"cell_type":"markdown","source":["Let's build a simple chain that combines 4 concepts:\n","\n","* Using chat messages as our graph state\n","* Using chat models in graph nodes\n","* Binding tools to our chat model\n","* Executing tool calls in graph nodes"],"metadata":{"id":"Ppcvaz2i4gPO"}},{"cell_type":"markdown","source":["### 1. Messages"],"metadata":{"id":"tzq9F9v29tDu"}},{"cell_type":"markdown","source":["Chat models can handle different types of messages representing various roles in a conversation. LangChain supports key message types like:\n","\n","* `HumanMessage` - from the user\n","* `AIMessage` - from the chat model\n","* `SystemMessage` - to guide the model's behavior\n","* `ToolMessage` - responses from tool calls\n","\n","Let's build a list of messages. Each message can include:\n","\n","* **content** - the message text\n","* **name** - optional author name\n","* **response_metadata** - optional metadata (e.g. from model providers for AIMessage, like OpenAI)\n"],"metadata":{"id":"lJ1J6vdl90rr"}},{"cell_type":"code","source":["from pprint import pprint\n","from langchain_core.messages import AIMessage, HumanMessage\n","\n","messages = [AIMessage(content=\"Hello, I'm your virtual travel assistant for Bengaluru. How can I help you plan your visit?\", name=\"Agent\")]\n","messages.append(HumanMessage(content=\"Hi, I'm visiting Bengaluru for the first time. Can you suggest key places to see?\", name=\"Miguel\"))\n","messages.append(AIMessage(content=\"Certainly. Some must-visit places include Lalbagh Botanical Garden, Bangalore Palace, and Cubbon Park. Are you interested in cultural sites, nature, or food experiences?\", name=\"Agent\"))\n","messages.append(HumanMessage(content=\"I'm interested in a mix of history and local cuisine.\", name=\"Miguel\"))\n","messages.append(AIMessage(content=\"Great choice. You can explore Tipu Sultan's Summer Palace for history, then head to VV Puram Food Street for authentic local dishes.\", name=\"Agent\"))\n","\n","for m in messages:\n","    m.pretty_print()\n"],"metadata":{"id":"urQ2ZyXU9uYI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chat Models"],"metadata":{"id":"u7nNj7VL-_c2"}},{"cell_type":"markdown","source":["Chat models accept a sequence of messages as input and support multiple message types, as previously mentioned.\n","\n","Among the available options, we'll be working with **OpenAI**.\n","\n","Before proceeding, we'll check if your `OPENAI_API_KEY` is configured. If it's not, you'll be prompted to provide it."],"metadata":{"id":"GeQQAsIIHiFz"}},{"cell_type":"code","source":["import os, getpass\n","\n","def _set_env(var: str):\n","    if not os.environ.get(var):\n","        os.environ[var] = getpass.getpass(f\"{var}: \")\n","\n","_set_env(\"OPENAI_API_KEY\")"],"metadata":{"id":"zKiQCaVP-v3M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model=\"gpt-4o\")\n","result = llm.invoke(messages)"],"metadata":{"id":"WF8bsJAwAZN-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see that the result is an `AIMessage` with specific `response_metadata`."],"metadata":{"id":"MZ1NJ0lnIJ4o"}},{"cell_type":"code","source":["type(result)"],"metadata":{"id":"Le3HNCU2AZLE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result.pretty_print()"],"metadata":{"id":"qRJ9mxHxISLg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see the content by accessing the `content` property."],"metadata":{"id":"v0kNNyeRIUnb"}},{"cell_type":"code","source":["result.content"],"metadata":{"id":"sZ5xuKagIT_h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Tools\n","\n"],"metadata":{"id":"hLK7Y0XhIcCU"}},{"cell_type":"markdown","source":["Tools are valuable when you need a model to interact with **external systems**.\n","\n","These systems (such as APIs) typically expect **structured inputs** rather than natural language.\n","\n","> By binding an API as a tool, you make the model aware of the expected input format.\n","\n","\n","The model decides when to call a tool based on the user's natural language input, and the output will follow the tool's defined schema.\n","\n","Many LLM providers now support tool calling, and LangChain offers a straightforward interface for it.\n","\n","You can bind any Python function using `ChatModel.bind_tools(function)`.\n","\n","\n"],"metadata":{"id":"g_AJB0zoIpLc"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1rzCEThHO58tv9YPPEu0jwKaoy7DS7XAL\" alt=\"Alt text\" width=\"700\"/>"],"metadata":{"id":"KmF0FoijJJbX"}},{"cell_type":"markdown","source":["Let's showcase a very simple example of tool calling. The `multiply` function is our tool."],"metadata":{"id":"ZUB_I6M-JKXV"}},{"cell_type":"code","source":["def multiply(a: int, b: int) -> int:\n","    \"\"\"Multiply a and b.\n","\n","    Args:\n","        a: first int\n","        b: second int\n","    \"\"\"\n","    return a * b\n","\n","llm_with_tools = llm.bind_tools([multiply])"],"metadata":{"id":"Kk_IxVcdIYmy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["no_tool_call = llm_with_tools.invoke(\n","    [HumanMessage(content=\"Hey! How are you?\", name=\"Miguel\")]\n",")"],"metadata":{"id":"_qB5xdmrDaPy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["no_tool_call.pretty_print()"],"metadata":{"id":"E6PzUt6WDkDV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["no_tool_call.content"],"metadata":{"id":"qYDNaTJ4DpCN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tool_call = llm_with_tools.invoke(\n","    [HumanMessage(content=f\"What is 2 multiplied by 3\", name=\"Miguel\")]\n",")"],"metadata":{"id":"d9EUrTwfJQvR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see a tool call return.\n","\n",">The tool call has specific arguments that match the input schema of our function along with the name of the function to call."],"metadata":{"id":"6NrTFoUqJZ5F"}},{"cell_type":"code","source":["tool_call.pretty_print()"],"metadata":{"id":"vYVr8RBqJWH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tool_call.content"],"metadata":{"id":"YzDkoB5HDn3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tool_call.tool_calls"],"metadata":{"id":"dVVP5rb9JZYH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Defining the State"],"metadata":{"id":"iuvZCUP_Jm7g"}},{"cell_type":"markdown","source":["Unlike the example graph we saw earlier, in this case we need to use `messages` (the message history) within the state.\n","\n","If we wanted to handle this manually, we'd need to create another `TypedDict` with a messages property."],"metadata":{"id":"vrgjmUWhJrCO"}},{"cell_type":"code","source":["from typing_extensions import TypedDict\n","from langchain_core.messages import AnyMessage\n","\n","class MessagesState(TypedDict):\n","    messages: list[AnyMessage]"],"metadata":{"id":"tiei1acPKNFq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fortunately, LangGraph already provides a built-in state type for this: `MessagesState`.\n","\n","The cool thing about this class is that it already incorporates a `reducer`. This reducer logic will take care of appending the new message to the message list.\n","\n","> All of these operations will be perform by LangGraph under the hood"],"metadata":{"id":"4TFw6j4fKLez"}},{"cell_type":"code","source":["from langgraph.graph import MessagesState\n","\n","class MessagesState(MessagesState):\n","    pass"],"metadata":{"id":"kUHuZ25WJiKx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Building the Graph"],"metadata":{"id":"dls1K3OzKp1p"}},{"cell_type":"code","source":["from IPython.display import Image, display\n","from langgraph.graph import StateGraph, START, END\n","\n","# Node\n","def tool_calling_llm(state: MessagesState):\n","    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n","\n","# Build graph\n","builder = StateGraph(MessagesState)\n","\n","builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n","\n","builder.add_edge(START, \"tool_calling_llm\")\n","builder.add_edge(\"tool_calling_llm\", END)\n","\n","graph = builder.compile()\n","\n","# View\n","display(Image(graph.get_graph().draw_mermaid_png()))"],"metadata":{"id":"nSwaEIwUKmTN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We've implemented a very simple chain!\n","\n","If we pass a general message (unrelated to math operations), the LLM will respond without any tool call."],"metadata":{"id":"7GFGtm1CKwrS"}},{"cell_type":"code","source":["messages = graph.invoke({\"messages\": HumanMessage(content=\"Hey there! I'm Miguel\")})\n","for m in messages['messages']:\n","    m.pretty_print()"],"metadata":{"id":"1zMqok4-KuWk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["But, if we ask about a multiplication, the LLM will use our tool."],"metadata":{"id":"ZklgmnC8K9Rh"}},{"cell_type":"code","source":["messages = graph.invoke({\"messages\": HumanMessage(content=\"Multiply 10 and 3\")})\n","for m in messages['messages']:\n","    m.pretty_print()"],"metadata":{"id":"L6eoDXRiK7uj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"aBR0990t5f9P"}},{"cell_type":"markdown","source":["## Router"],"metadata":{"id":"eAda2e9VLdXs"}},{"cell_type":"markdown","source":["You can think of this as a **router**, where the chat model decidesâ€”based on user inputâ€”whether to respond directly or to call a tool.\n","\n","This represents a basic form of an agent, where the LLM manages control flow by choosing between tool invocation and generating a direct reply."],"metadata":{"id":"Ag8oIyEbLqRG"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=18D4oguG3jAxr9GoQJcHZUevxcEdudkHh\" alt=\"Alt text\" width=\"700\"/>\n"],"metadata":{"id":"iYYNVAjMMS9_"}},{"cell_type":"markdown","source":["Let's extend the Chain example (the tool calling chain) like this:\n","\n","(1) Add a node that will call our tool\n","\n","(2) Add a conditional edge that will look at the chat model output, and route to our tool calling node or simply end if no tool call is performed"],"metadata":{"id":"6dolDRujMUiZ"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","def multiply(a: int, b: int) -> int:\n","    \"\"\"Multiply a and b.\n","\n","    Args:\n","        a: first int\n","        b: second int\n","    \"\"\"\n","    return a * b\n","\n","llm = ChatOpenAI(model=\"gpt-4o\")\n","llm_with_tools = llm.bind_tools([multiply])"],"metadata":{"id":"xpM2wDs5Lc6n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" We use the built-in `ToolNode` and simply pass a list of our tools to initialize it.\n","\n"," We use the built-in `tools_condition` as our conditional edge."],"metadata":{"id":"bkbgZG8IMs2_"}},{"cell_type":"code","source":["from IPython.display import Image, display\n","from langgraph.graph import StateGraph, START, END\n","from langgraph.graph import MessagesState\n","from langgraph.prebuilt import ToolNode\n","from langgraph.prebuilt import tools_condition\n","\n","# Node\n","def tool_calling_llm(state: MessagesState):\n","    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n","\n","# Build graph\n","builder = StateGraph(MessagesState)\n","\n","builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n","builder.add_node(\"tools\", ToolNode([multiply]))\n","\n","builder.add_edge(START, \"tool_calling_llm\")\n","builder.add_conditional_edges(\n","    \"tool_calling_llm\",\n","    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n","    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n","    tools_condition,\n",")\n","builder.add_edge(\"tools\", END)\n","\n","graph = builder.compile()\n","\n","# View\n","display(Image(graph.get_graph().draw_mermaid_png()))"],"metadata":{"id":"AuksFCwKMqQ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.messages import HumanMessage\n","messages = [HumanMessage(content=\"Hello, what is 2 multiplied by 2?\")]\n","messages = graph.invoke({\"messages\": messages})\n","for m in messages['messages']:\n","    m.pretty_print()"],"metadata":{"id":"7Gi0nmCYMzjp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"M60IiYd_5jIU"}},{"cell_type":"markdown","source":["## ReAct Agent"],"metadata":{"id":"k2r0zMaqCKcS"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1HSQUzZAkCv_Ec-1EES1yZZFCPKizISsW\" alt=\"Alt text\" width=\"700\"/>"],"metadata":{"id":"zhUovpg2DD7b"}},{"cell_type":"markdown","source":["The ReAct pattern is one of the most common for agentic architectures. It's the one we'll be using for our Telegram Bot as well.\n","\n","You can think of it as an evolution of the Router pattern.\n","\n","In the router above, we invoked the model â€” and if it decided to call a tool, we returned a ToolMessage to the user.\n","\n","But what if, instead, we passed that ToolMessage back to the model?\n","\n","\n","That way, it gets to decide what's next:\n","\n","(1) **Call another tool**\n","\n","(2) **Respond directly**\n","\n","ReAct stands for \"Reason + Act\", and can be easily understood by the following diagram."],"metadata":{"id":"U3TTaZQ8CPNd"}},{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?id=1BfpjPboaDU0fJ1dtuuBuVhjZxRlVDJB1\" alt=\"Alt text\" width=\"700\"/>"],"metadata":{"id":"ZYhqDTImEWcW"}},{"cell_type":"markdown","source":["To test how the ReAct architecture works, let's create three tools instead of one."],"metadata":{"id":"4U4GTsN5EiM-"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","def multiply(a: int, b: int) -> int:\n","    \"\"\"Multiply a and b.\n","\n","    Args:\n","        a: first int\n","        b: second int\n","    \"\"\"\n","    return a * b\n","\n","def add(a: int, b: int) -> int:\n","    \"\"\"Adds a and b.\n","\n","    Args:\n","        a: first int\n","        b: second int\n","    \"\"\"\n","    return a + b\n","\n","def divide(a: int, b: int) -> float:\n","    \"\"\"Divide a and b.\n","\n","    Args:\n","        a: first int\n","        b: second int\n","    \"\"\"\n","    return a / b\n","\n","tools = [add, multiply, divide]"],"metadata":{"id":"B5K0SJznCuH9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, let's bind the three tools to the OpenAI ChatModel."],"metadata":{"id":"YraxyoHFEzRA"}},{"cell_type":"code","source":["llm = ChatOpenAI(model=\"gpt-4o\")\n","llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)"],"metadata":{"id":"AOeX0tSTEylI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's create a simple node for defining the assistant behaviour."],"metadata":{"id":"df4kUJDyFH8A"}},{"cell_type":"code","source":["from langgraph.graph import MessagesState\n","from langchain_core.messages import HumanMessage, SystemMessage\n","\n","sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic operations\")\n","\n","\n","def assistant(state: MessagesState):\n","  return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"],"metadata":{"id":"-KTMZs20E8qY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally, let's build and compile the graph."],"metadata":{"id":"USITiDwPFTaO"}},{"cell_type":"code","source":["from langgraph.graph import START, StateGraph\n","from langgraph.prebuilt import tools_condition\n","from langgraph.prebuilt import ToolNode\n","from IPython.display import Image, display\n","\n","builder = StateGraph(MessagesState)\n","\n","builder.add_node(\"assistant\", assistant)\n","builder.add_node(\"tools\", ToolNode(tools))\n","\n","builder.add_edge(START, \"assistant\")\n","builder.add_conditional_edges(\n","    \"assistant\",\n","    tools_condition,\n",")\n","\n","# IMPORTANT! -> Now the 'tools' node points back to the 'assistant' node, creating a loop\n","builder.add_edge(\"tools\", \"assistant\")\n","react_graph = builder.compile()\n","\n","display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"],"metadata":{"id":"5QT4bqmWFQ2B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's try it out ..."],"metadata":{"id":"nJSVbbyNGAeQ"}},{"cell_type":"code","source":["messages = [HumanMessage(content=\"Add 10 and 5. Multiply the output by 2. Divide the output by 5\")]\n","messages = react_graph.invoke({\"messages\": messages})"],"metadata":{"id":"DqtwkZaEFe7t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for m in messages['messages']:\n","  m.pretty_print()"],"metadata":{"id":"LDNsOPhrFmyv"},"execution_count":null,"outputs":[]}]}